'''
Script to handle analysis of patient IRM and seg
'''
# Dependencies
import base64
import nibabel as nib
import numpy as np
import cv2
import io
from PIL import Image
from google.cloud import aiplatform

from back_environment import PROJECT_ID, REGION, MEDGEMMA_FT_ENDPOINT_ID, MEDGEMMA_FT_ENDPOINT_REGION

def run_analysis(id):

    # Run Gemma FineTuned on all images
    #          Images in seg are supposed to be pre-processed to already have the segmentations applied

    # INIT PLATFORM AND ENDPOINT
    aiplatform.init(project=PROJECT_ID, location=REGION)

    endpoint = aiplatform.Endpoint(
        endpoint_name=MEDGEMMA_FT_ENDPOINT_ID,
        project=PROJECT_ID,
        location=MEDGEMMA_FT_ENDPOINT_REGION,
    )

    # Load MRI data using nibabel and process each slice
    mri_file_path = f"./front/public/mri/{id}.seg/mri_file.nii"
    
    # Load the NIfTI file
    img = nib.load(mri_file_path)
    data = img.get_fdata()

    # Prompt 
    BRAIN_CLASSES = [
        "A: frontal",
        "B: occipital",
        "C: parietal",
        "D: temporal",
    ]
    options = "\n".join(BRAIN_CLASSES)
    PROMPT = f"What brain region does the edema span the most?\n{options}"
    formatted_prompt = f"{PROMPT} <start_of_image>"
    
    # Process each slice and encode to base64
    slice_predictions = []
    
    for slice_idx in range(data.shape[0]):
        # Extract the slice
        slice_data = data[slice_idx]

        # Encode to png
        success, encoded_image = cv2.imencode('.png', slice_data)
        # Encode the bytes to base64
        img_b64 = base64.b64encode(encoded_image).decode('utf-8')

        # Instance and Message
        instances = [
            {
                "prompt": formatted_prompt,
                "multi_modal_data": {"image": f'data:image/png;base64,{img_b64}' },
                "max_tokens": 500,
                "temperature": 0,
                "raw_response": False,
            },
        ]

        # Run Inference
        response = endpoint.predict(
            instances=instances, use_dedicated_endpoint=True
        )


        # Display
        prediction = response.predictions[0]